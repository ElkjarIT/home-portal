# ─────────────────────────────────────────────────────────────────────────────
# Immich backend stack — Chappie (Windows 11 / Docker Desktop / WSL2)
# ─────────────────────────────────────────────────────────────────────────────
#
# Runs Immich background workers (video transcode, thumbnails, smart-search,
# face detection, etc.) with the API/web layer disabled, plus a co-located
# machine-learning server for CUDA-accelerated inference on the RTX 3080.
#
# The primary Immich server on the Proxmox VM remains the frontend (web UI,
# mobile app, API). When Chappie is offline the primary handles everything
# on its own — no migration or cleanup needed.
#
# Prerequisites:
#   Create the Docker CIFS volume once before first start (see .env.example):
#   docker volume create --driver local --opt type=cifs \
#     --opt device=//10.10.40.40/immich-data \
#     "--opt" "o=addr=10.10.40.40,username=odin,password=<SMB_PASS>,uid=1000,gid=1000,file_mode=0660,dir_mode=0770" \
#     immich-data
#
# Usage (CPU transcoding):
#   cp .env.example .env    # fill in DB_* and REDIS_*
#   docker compose up -d
#
# Usage (NVIDIA NVENC + CUDA hardware acceleration):
#   docker compose -f docker-compose.yml -f docker-compose.hwaccel.yml up -d
#
# Graceful shutdown:
#   docker compose down     # running jobs re-queue; primary server continues
# ─────────────────────────────────────────────────────────────────────────────

name: immich-worker

services:
  immich-worker:
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    container_name: immich_worker
    restart: unless-stopped

    # No ports published — this node has no web UI or API surface.

    environment:
      # Disable the API server; run only background microservices workers.
      IMMICH_WORKERS_EXCLUDE: "api"

      # ── Upload/library paths — MUST match the primary server's configuration ──
      # The primary server uses /opt/immich/uploads inside the container.
      UPLOAD_LOCATION: /opt/immich/uploads
      IMMICH_MEDIA_LOCATION: /opt/immich/uploads

      # ── Database (primary server) ─────────────────────────────────────────
      DB_HOSTNAME: ${DB_HOSTNAME}
      DB_PORT: ${DB_PORT:-5432}
      DB_USERNAME: ${DB_USERNAME}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_DATABASE_NAME: ${DB_DATABASE_NAME}

      # ── Redis (primary server) ────────────────────────────────────────────
      REDIS_HOSTNAME: ${REDIS_HOSTNAME}
      REDIS_PORT: ${REDIS_PORT:-6379}

      TZ: ${TZ:-Europe/Copenhagen}

    volumes:
      # Docker-native CIFS volume mounting the full /data/immich root at /opt/immich.
      # This gives the worker access to uploads, icloud, messages and all other paths
      # that assets may reference — matching the primary server's full volume layout.
      # Create with `docker volume create immich-data ...` before first start (see header).
      - immich-data:/opt/immich

    depends_on:
      - immich-machine-learning

  immich-machine-learning:
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    container_name: immich_machine_learning
    restart: unless-stopped
    volumes:
      - model-cache:/cache
    environment:
      MACHINE_LEARNING_WORKERS: 1
      TZ: ${TZ:-Europe/Copenhagen}

volumes:
  immich-data:
    external: true   # Created separately via docker volume create (see header)
  model-cache:       # Local volume for ML model cache — persists across restarts
