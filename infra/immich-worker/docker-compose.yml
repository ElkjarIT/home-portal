# ─────────────────────────────────────────────────────────────────────────────
# Immich GPU worker — Chappie (Windows 11 / Docker Desktop / WSL2)
# ─────────────────────────────────────────────────────────────────────────────
#
# Runs **only GPU-accelerated** Immich workers:
#   - videoConversion       (NVENC hardware transcode)
#   - thumbnailGeneration   (image processing)
#   - smartSearch           (CLIP embeddings — CUDA)
#   - faceDetection         (face detection — CUDA)
#   - facialRecognition     (face recognition — CUDA)
#
# I/O-heavy workers (metadataExtraction, sidecar, library, migration, etc.)
# stay on the primary Proxmox server where storage is local via iSCSI.
# This avoids exiftool 120 s timeouts reading large .MOV files over NFS/1 GbE.
#
# The primary Immich server on the Proxmox VM remains the frontend (web UI,
# mobile app, API). When Chappie is offline the primary handles everything
# on its own — no migration or cleanup needed.
#
# Prerequisites:
#   Create the Docker NFS volume once before first start (see .env.example):
#   docker volume create --driver local --opt type=nfs \
#     --opt "o=addr=10.10.40.40,rw,nfsvers=4.1,rsize=1048576,wsize=1048576,hard,timeo=600,retrans=2,noresvport" \
#     --opt device=":/data/immich" \
#     immich-data
#
# Usage (CPU transcoding):
#   cp .env.example .env    # fill in DB_*, REDIS_*
#   docker compose up -d
#
# Usage (NVIDIA NVENC hardware acceleration):
#   docker compose -f docker-compose.yml -f docker-compose.hwaccel.yml up -d
#
# Graceful shutdown:
#   docker compose down     # running jobs re-queue; primary server continues
# ─────────────────────────────────────────────────────────────────────────────

name: immich-worker

services:
  immich-worker:
    image: ghcr.io/immich-app/immich-server:${IMMICH_VERSION:-release}
    container_name: immich_worker
    restart: unless-stopped

    # No ports published — this node has no web UI or API surface.

    environment:
      # Disable the API server; run only background microservices workers.
      # Note: Immich v2.5.x only supports "api" and "microservices" as worker
      # types — fine-grained queue selection is not available.
      IMMICH_WORKERS_EXCLUDE: "api"

      # ── Upload/library paths — MUST match the primary server's configuration ──
      UPLOAD_LOCATION: /opt/immich/uploads
      IMMICH_MEDIA_LOCATION: /opt/immich/uploads

      # ── ML server — local instance on the same Docker network ──────────────
      IMMICH_MACHINE_LEARNING_URL: http://immich-machine-learning:3003

      # ── Database (primary server) ─────────────────────────────────────────
      DB_HOSTNAME: ${DB_HOSTNAME}
      DB_PORT: ${DB_PORT:-5432}
      DB_USERNAME: ${DB_USERNAME}
      DB_PASSWORD: ${DB_PASSWORD}
      DB_DATABASE_NAME: ${DB_DATABASE_NAME}

      # ── Redis (primary server) ────────────────────────────────────────────
      REDIS_HOSTNAME: ${REDIS_HOSTNAME}
      REDIS_PORT: ${REDIS_PORT:-6379}

      TZ: ${TZ:-Europe/Copenhagen}

    volumes:
      # Docker-native NFS volume mounting the full /data/immich root at /opt/immich.
      - immich-data:/opt/immich

  immich-machine-learning:
    image: ghcr.io/immich-app/immich-machine-learning:${IMMICH_VERSION:-release}
    container_name: immich_machine_learning
    restart: unless-stopped
    volumes:
      - model-cache:/cache
    environment:
      MACHINE_LEARNING_WORKERS: 3
      MACHINE_LEARNING_REQUEST_THREADS: 4
      TZ: ${TZ:-Europe/Copenhagen}

volumes:
  immich-data:
    external: true   # Created separately via docker volume create (see header)
  model-cache:
